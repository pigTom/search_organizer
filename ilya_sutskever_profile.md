# Ilya Sutskever 人物资料

> 本文档整理了人工智能领域重要人物 Ilya Sutskever 的生平资料、学术成就、公开资源和核心思想。
> 最后更新：2026年1月

---

## 目录

1. [人物简介](#1-人物简介)
2. [人生时间轴](#2-人生时间轴)
3. [学术成就](#3-学术成就)
4. [公开资源](#4-公开资源)
5. [核心思想与观点](#5-核心思想与观点)
6. [荣誉与奖项](#6-荣誉与奖项)
7. [Ilya 推荐阅读列表](#7-ilya-推荐阅读列表)
8. [参考链接汇总](#8-参考链接汇总)

---

## 1. 人物简介

### 基本信息

| 项目 | 内容 |
|------|------|
| **姓名** | Ilya Sutskever（伊利亚·苏茨克维） |
| **出生** | 1986年，俄罗斯下诺夫哥罗德（苏联时期的高尔基市） |
| **国籍** | 以色列-加拿大 |
| **领域** | 人工智能、深度学习、神经网络 |
| **教育** | 多伦多大学计算机科学博士（导师：Geoffrey Hinton） |
| **现职** | Safe Superintelligence Inc. (SSI) CEO |

### 核心贡献概述

Ilya Sutskever 是当代最具影响力的人工智能科学家之一，他的主要贡献包括：

- **AlexNet (2012)**：与 Alex Krizhevsky、Geoffrey Hinton 共同开发，开启了深度学习革命
- **Seq2Seq (2014)**：序列到序列学习，奠定了现代机器翻译的基础
- **GPT 系列**：作为 OpenAI 首席科学家，领导了 GPT-1 到 GPT-4 的开发
- **CLIP & DALL-E**：推动了多模态AI的发展
- **AI 安全研究**：创办 SSI，专注于安全超级智能的研发

---

## 2. 人生时间轴

### 早年生活 (1986-2002)

| 年份 | 事件 |
|------|------|
| **1986** | 出生于俄罗斯下诺夫哥罗德（苏联高尔基市） |
| **1991** | 5岁时随家人移民以色列，定居耶路撒冷 |
| **2000-2002** | 就读以色列开放大学 |
| **2002** | 16岁时随家人移民加拿大 |

> 来源：[Wikipedia - Ilya Sutskever](https://en.wikipedia.org/wiki/Ilya_Sutskever)

### 学术生涯 (2002-2013)

| 年份 | 事件 |
|------|------|
| **2005** | 获得多伦多大学数学学士学位 |
| **2007** | 获得多伦多大学计算机科学硕士学位 |
| **2008-2011** | 在 Geoffrey Hinton 指导下进行 RNN 研究，发表多篇重要论文 |
| **2012** | 与 Krizhevsky、Hinton 共同开发 AlexNet，在 ImageNet 竞赛中取得突破性成果 |
| **2013** | 获得多伦多大学计算机科学博士学位，论文题目《Training Recurrent Neural Networks》 |
| **2013** | 在 Andrew Ng 指导下于斯坦福大学进行短期博士后研究 |
| **2013** | 与 Hinton、Krizhevsky 共同创办 DNNResearch，随后被 Google 收购 |

> 来源：[University of Toronto News](https://www.utoronto.ca/news/neural-net-behind-geoffrey-hinton-s-nobel-prize-be-preserved-computer-history-museum), [Wikipedia](https://en.wikipedia.org/wiki/Ilya_Sutskever)

### Google Brain 时期 (2013-2015)

| 年份 | 事件 |
|------|------|
| **2013** | 加入 Google Brain 担任研究科学家 |
| **2014** | 与 Oriol Vinyals、Quoc Le 共同开发 Seq2Seq 序列学习算法 |
| **2014-2015** | 参与 TensorFlow 的开发 |
| **2015** | 离开 Google，联合创办 OpenAI |

> 来源：[Wikipedia](https://en.wikipedia.org/wiki/Ilya_Sutskever), [Google Research](https://research.google/pubs/tensorflow-large-scale-machine-learning-on-heterogeneous-distributed-systems/)

### OpenAI 时期 (2015-2024)

| 年份 | 事件 |
|------|------|
| **2015年12月** | 联合创办 OpenAI，担任首席科学家和董事会成员 |
| **2017** | 参与发表《Learning to Generate Reviews and Discovering Sentiment》 |
| **2018** | 发表 GPT-1 论文《Improving Language Understanding by Generative Pre-Training》 |
| **2019** | 发表 GPT-2 论文《Language Models are Unsupervised Multitask Learners》 |
| **2019** | 发表《Dota 2 with Large Scale Deep Reinforcement Learning》，OpenAI Five 击败人类职业选手 |
| **2020** | GPT-3 发布 |
| **2021** | 发表 CLIP 和 DALL-E 论文 |
| **2022** | Whisper 语音识别模型发布 |
| **2023年3月** | GPT-4 发布 |
| **2023年7月** | 与 Jan Leike 共同领导 Superalignment 超级对齐团队 |
| **2023年11月17日** | 参与 OpenAI 董事会解雇 Sam Altman 事件 |
| **2023年11月20日** | 公开表达对参与解雇 Altman 的遗憾，签署要求恢复 Altman 的员工信 |
| **2023年11月22日** | Altman 恢复 CEO 职位，Sutskever 退出董事会 |
| **2023年12月** | 发表《Weak-to-Strong Generalization》论文 |
| **2024年5月14日** | 宣布离开 OpenAI |

> 来源：[AP News](https://apnews.com/article/419276b50007ad41adfd27764da3188c), [Time](https://time.com/6337102/sam-altman-departs-openai/), [OpenAI Blog](https://openai.com/index/introducing-superalignment/)

### SSI 时期 (2024-至今)

| 年份 | 事件 |
|------|------|
| **2024年6月19日** | 与 Daniel Gross、Daniel Levy 共同创办 Safe Superintelligence Inc. (SSI) |
| **2024年9月** | SSI 获得10亿美元融资，估值50亿美元（投资方包括 Andreessen Horowitz、Sequoia Capital 等） |
| **2025年3月** | SSI 再获20亿美元融资，估值达300亿美元 |
| **2025年4月** | SSI 与 Google Cloud 建立合作，使用 TPU 进行 AI 研究 |
| **2025年7月** | Daniel Gross 离开加入 Meta，Sutskever 担任 CEO，Daniel Levy 担任总裁 |

> 来源：[TechCrunch](https://techcrunch.com/2024/09/04/ilya-sutskevers-startup-safe-super-intelligence-raises-1b/), [Time](https://time.com/6990076/safe-superintelligence-inc-announced/), [The AI Insider](https://theaiinsider.tech/2025/03/10/ilya-sutskevers-safe-superintelligence-raises-2b-valuing-ai-startup-at-30b/)

---

## 3. 学术成就

### 博士论文

**Training Recurrent Neural Networks** (2013)
- 机构：多伦多大学
- 导师：Geoffrey Hinton
- 内容：探讨有效训练循环神经网络的方法和挑战
- 链接：[PDF](https://www.cs.toronto.edu/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)

### 重要论文列表

以下按时间顺序列出 Ilya Sutskever 参与的重要论文：

#### 早期研究 (2008-2011)

| 年份 | 论文标题 | 合作者 | 简介 |
|------|----------|--------|------|
| 2010 | Temporal-Kernel Recurrent Neural Networks | Geoffrey Hinton | 引入时间核的 RNN 变体 |
| 2011 | Generating Text with Recurrent Neural Networks | James Martens, Geoffrey Hinton | 字符级语言建模 |
| 2011 | Learning Recurrent Neural Networks with Hessian-Free Optimization | James Martens | 使用 Hessian-Free 优化训练 RNN |

> 来源：[University of Toronto CS](https://www.cs.utoronto.ca/~ilya/pubs/)

#### AlexNet 与深度学习革命 (2012)

| 年份 | 论文标题 | 合作者 | 链接 |
|------|----------|--------|------|
| 2012 | **ImageNet Classification with Deep Convolutional Neural Networks** | Alex Krizhevsky, Geoffrey Hinton | [NeurIPS](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html) |

> **历史意义**：AlexNet 在 ImageNet 竞赛中以压倒性优势获胜，将错误率从 26% 降至 15.3%，标志着深度学习时代的开始。

#### Seq2Seq 与序列学习 (2014-2015)

| 年份 | 论文标题 | 合作者 | 链接 |
|------|----------|--------|------|
| 2014 | **Sequence to Sequence Learning with Neural Networks** | Oriol Vinyals, Quoc V. Le | [arXiv:1409.3215](https://arxiv.org/abs/1409.3215) |
| 2014 | Recurrent Neural Network Regularization | Wojciech Zaremba, Oriol Vinyals | [arXiv:1409.2329](https://arxiv.org/abs/1409.2329) |
| 2015 | Neural Programmer: Inducing Latent Programs with Gradient Descent | Arvind Neelakantan, Quoc V. Le | [arXiv:1511.04834](https://arxiv.org/abs/1511.04834) |
| 2015 | Neural Random-Access Machines | Karol Kurach, Marcin Andrychowicz | [arXiv:1511.06392](https://arxiv.org/abs/1511.06392) |

#### OpenAI 时期 (2017-2023)

| 年份 | 论文标题 | 简介 | 链接 |
|------|----------|------|------|
| 2017 | Learning to Generate Reviews and Discovering Sentiment | 无监督情感发现 | OpenAI |
| 2018 | **Improving Language Understanding by Generative Pre-Training (GPT-1)** | GPT 架构的奠基之作 | OpenAI |
| 2019 | Language Models are Unsupervised Multitask Learners (GPT-2) | 展示大规模语言模型的多任务能力 | OpenAI |
| 2019 | Generating Long Sequences with Sparse Transformers | 稀疏注意力机制 | [arXiv:1904.10509](https://arxiv.org/abs/1904.10509) |
| 2019 | Dota 2 with Large Scale Deep Reinforcement Learning | OpenAI Five | [arXiv:1912.06680](https://arxiv.org/abs/1912.06680) |
| 2020 | Generative Language Modeling for Automated Theorem Proving | 自动定理证明 | [OpenReview](https://openreview.net/pdf?id=kDakBhOaBV) |
| 2021 | **Zero-Shot Text-to-Image Generation (DALL-E)** | 文本到图像生成 | [arXiv:2102.12092](https://arxiv.org/abs/2102.12092) |
| 2021 | **Learning Transferable Visual Models From Natural Language Supervision (CLIP)** | 多模态视觉-语言模型 | [arXiv:2103.00020](https://arxiv.org/abs/2103.00020) |
| 2021 | Evaluating Large Language Models Trained on Code (Codex) | 代码生成模型 | [arXiv:2107.03374](https://arxiv.org/abs/2107.03374) |
| 2022 | Robust Speech Recognition via Large-Scale Weak Supervision (Whisper) | 语音识别 | [arXiv:2212.04356](https://arxiv.org/abs/2212.04356) |
| 2023 | **Weak-to-Strong Generalization** | 弱监督引导强模型 | [arXiv:2312.09390](https://arxiv.org/abs/2312.09390) |

---

## 4. 公开资源

### 演讲与会议报告

| 日期 | 标题 | 场合 | 内容概要 | 链接 |
|------|------|------|----------|------|
| 2014 | Sequence to Sequence Learning with Neural Networks | NIPS 2014 Oral | Seq2Seq 模型介绍 | [Microsoft Research](https://www.microsoft.com/en-us/research/video/nips-oral-session-4-ilya-sutskever/) |
| 2020.10 | The Unreasonable Effectiveness of Large Generative Models | Harvard ML Foundations | 回顾 GPT-3 的能力与局限 | [ML Foundations](https://mlfoundations.org/talk/ilya/) |
| 2024.12 | **Pre-Training as We Know It Will End** | NeurIPS 2024 Keynote | 预测预训练范式的终结，讨论超级智能的自我意识和不可预测性 | [YouTube](https://www.youtube.com/watch?v=YM_8mBnv-EI) |

> NeurIPS 2024 演讲核心观点：
> - 互联网数据有限，预训练无法无限扩展
> - 未来 AI 需要自己生成数据或评估多个答案
> - 超级智能 AI 将具有自我意识，行为更难预测
### 播客访谈

| 日期 | 播客/节目 | 主持人 | 内容概要 | 链接 |
|------|-----------|--------|----------|------|
| 2020.05.08 | **Lex Fridman Podcast #94** | Lex Fridman | 深度学习基础、AlexNet、RNN、语言与视觉问题 | [Lex Fridman](https://lexfridman.com/ilya-sutskever/) |
| 2023.03.27 | **Dwarkesh Podcast** | Dwarkesh Patel | AGI 时间线、超人 AI 对齐挑战、AI 研究范式未来 | [Dwarkesh Patel](https://www.dwarkeshpatel.com/p/ilya-sutskever) |
| 2023.04.26 | Stanford eCorner Talk | Ravi Belani | OpenAI 决策方法、深度学习未来预测 | [Stanford PDF](https://stvp.stanford.edu/wp-content/uploads/sites/3/2024/09/inside-openai-entire-talk-transcript.pdf) |
| 2025.11.25 | Dwarkesh Podcast (第二次) | Dwarkesh Patel | 从扩展时代到研究时代的转变、AGI 安全开发 | [Scripod](https://scripod.com/episode/jwdqt7aia2v3j21wd2debstd) |
| 2025.12.15 | The a16z Show | a16z | AGI 进展障碍、强化学习与预训练的区别、AI 驱动的经济 | [Podbay](https://podbay.fm/p/the-a16z-show/e/1765796400) |

### 视频与播客

| 日期 | 标题 | 场合/平台 | 内容概要 | 链接 |
|------|------|-----------|----------|------|
| 2018 | NVIDIA NTECH Keynote | NVIDIA 内部工程大会 | AI 在复杂游戏（Dota 2）中超越人类表现，强化学习扩展与领域随机化 | [YouTube](https://www.youtube.com/watch?v=SUbqykXVx0A) |
| 2020.05.08 | **Lex Fridman Podcast #94: Deep Learning** | Lex Fridman Podcast | AlexNet、成本函数、RNN、语言与视觉问题的挑战 | [YouTube](https://www.youtube.com/watch?v=13CZPWmke6A) |
| 2023 | **The Exciting, Perilous Journey Toward AGI** | TED Talk | AGI 的变革潜力与风险，探讨 AGI 如何超越人类智能并影响医疗等领域 | [YouTube](https://www.youtube.com/watch?v=SEkGLj0bwAU) |
| 2023.04 | Inside OpenAI | Stanford eCorner | OpenAI 的决策方法、深度学习未来预测 | [Stanford](https://stvp.stanford.edu/videos/inside-openai-entire-talk/) |
| 2023.11.02 | **Ilya: The AI Scientist Shaping the World** | The Guardian 纪录片 | 创立愿景、个人哲学、AI 对世界的影响预测 | [The Guardian](https://www.theguardian.com/technology/video/2023/nov/02/ilya-the-ai-scientist-shaping-the-world) |
| 2024.06 | Safe SuperIntelligence Inc. 公告 | YouTube | SSI 公司成立介绍 | [YouTube](https://www.youtube.com/watch?v=_esucEIgIeg) |
| 2024.12 | **NeurIPS 2024 Keynote: Pre-Training as We Know It Will End** | NeurIPS 2024 | 预训练范式终结预测、超级智能的自我意识与不可预测性 | [YouTube](https://www.youtube.com/watch?v=YM_8mBnv-EI) |


### 学术会议演讲

| 日期 | 标题 | 会议 | 内容概要 | 链接 |
|------|------|------|----------|------|
| 2014 | Sequence to Sequence Learning with Neural Networks | NIPS 2014 Oral Session | Seq2Seq 模型介绍与演示 | [Microsoft Research](https://www.microsoft.com/en-us/research/video/nips-oral-session-4-ilya-sutskever/) |
| 2020.10 | The Unreasonable Effectiveness of Large Generative Models | Harvard ML Foundations | 回顾 GPT-3 的能力、涌现特性与局限 | [ML Foundations](https://mlfoundations.org/talk/ilya/) |
| 2024.12 | **Pre-Training as We Know It Will End** | NeurIPS 2024 Keynote | 互联网数据有限性、未来AI需自生成数据、超级智能不可预测性 | [YouTube](https://www.youtube.com/watch?v=YM_8mBnv-EI) |

> **NeurIPS 2024 演讲核心观点**：
> - 互联网数据有限，预训练无法无限扩展
> - 未来 AI 需要自己生成数据或评估多个答案
> - 超级智能 AI 将具有自我意识，行为更难预测

### Bilibili 视频资源（中文字幕）

| 标题 | 内容概要 | 链接 |
|------|----------|------|
| 多伦多大学荣誉学位演讲 | AI 对人类社会的深远影响（2025年荣誉博士授予仪式） | [Bilibili BV1WQT6zxEun](https://www.bilibili.com/video/BV1WQT6zxEun/) |
| 黄仁勋与 Ilya Sutskever 炉边谈话 | NVIDIA CEO 与 Ilya 探讨 AI 未来发展 | [Bilibili BV1Tc411L7UA](https://www.bilibili.com/video/BV1Tc411L7UA/) |
| 深度访谈：AGI、ChatGPT 与机器人 | 通用人工智能、ChatGPT 技术原理、机器人发展 | [Bilibili BV1pF4m1j7Kb](https://www.bilibili.com/video/BV1pF4m1j7Kb/) |
| 斯坦福大学完整演讲 | Ilya 在斯坦福分享 AI 见解（中文字幕） | [Bilibili BV1Y24y1F72o](https://www.bilibili.com/video/BV1Y24y1F72o/) |

> **观看建议**：
> - 入门推荐：Lex Fridman Podcast #94（深度学习基础讲解）
> - 深度理解：Dwarkesh Podcast 2023（AGI 时间线与对齐挑战）
> - 最新观点：NeurIPS 2024 Keynote（预训练范式终结预测）
> - 中文观众：Bilibili 上的中文字幕视频更易理解

---

## 5. 核心思想与观点

### 关于 AI 意识

> "It may be that today's large neural networks are slightly conscious."
> （可能今天的大型神经网络已经有轻微的意识了。）
> — Ilya Sutskever, 2022年2月

来源：[Israel AI Online](https://israelaionline.com/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/)

### 关于超级智能

> "Superintelligent AI systems will be different, qualitatively... they may become agentic in a real way, capable of reasoning and self-awareness."
> （超级智能 AI 系统将在质上完全不同...它们可能真正成为有行动能力的实体，具备推理和自我意识能力。）
> — NeurIPS 2024 演讲

来源：[TechCrunch](https://techcrunch.com/2024/12/13/openai-co-founder-ilya-sutskever-believes-superintelligent-ai-will-be-unpredictable/)

### 关于 AI 研究范式

> "Is the belief that if you just 100x the scale, everything would be transformed? I don't think that's true. So it's back to the age of research again, just with big computers."
> （认为只要将规模扩大100倍，一切就会改变？我不认为这是真的。所以我们又回到了研究时代，只是现在有了大型计算机。）

来源：[Calcalist](https://www.calcalistech.com/ctechnews/article/h1fudk7z11x)

### 关于 AI 对齐

> "Parents care very deeply about the well-being of their children. It can be done. How does this imprinting work?"
> （父母非常关心孩子的幸福。这是可以做到的。这种印记是如何起作用的？）

来源：[Time](https://qa.time.com/6309011/ilya-sutskever-3/)

### 关于 AI 安全

> "Building safe superintelligence (SSI) is the most important technical problem of our time."
> （构建安全的超级智能是我们这个时代最重要的技术问题。）

### 关于 AI 的未来影响

> "The rate of progress will become really extremely fast for some time at least, resulting in unimaginable things. And in some sense, whether you like it or not, your life is going to be affected by AI to a great extent."
> （进步的速度将会在一段时间内变得极其快速，产生难以想象的结果。无论你喜欢与否，你的生活都将在很大程度上受到 AI 的影响。）

来源：[Global Advisors](https://globaladvisors.biz/2025/07/05/quote-ilya-sutskever-safe-superintelligence/)

---

## 6. 荣誉与奖项

| 年份 | 荣誉 | 授予机构 |
|------|------|----------|
| 2015 | **MIT Technology Review 35 Innovators Under 35** | MIT Technology Review |
| 2022 | **Fellow of the Royal Society (FRS)** | 英国皇家学会 |
| 2023 | Time 100 AI Most Influential People | Time 杂志 |
| 2024 | Time 100 AI Most Influential People | Time 杂志 |
| 2025 | 荣誉博士学位 | 多伦多大学 |

> 来源：[Royal Society](https://royalsociety.org/people/ilya-sutskever-35834/), [Wikipedia](https://en.wikipedia.org/wiki/Ilya_Sutskever)

---

## 7. Ilya 推荐阅读列表

Ilya Sutskever 曾向 John Carmack 推荐了约30篇研究论文，称"如果你真正学会了这些，你就掌握了当今 AI 领域90%的重要知识"。以下是该列表的整理：

### 7.1 基础理论

| 论文/资源 | 作者 | 主题 |
|-----------|------|------|
| Keeping Neural Networks Simple | Geoffrey Hinton, Drew van Camp | 模型压缩与最小描述长度原则 |
| A Tutorial Introduction to the Minimum Description Length Principle | Peter Grunwald | 统计模型选择 |
| Kolmogorov Complexity and Algorithmic Randomness | A. Shen, V. Uspensky, N. Vereshchagin | 压缩与随机性理论基础 |
| Machine Super Intelligence | Shane Legg | 超级智能机器的挑战 |

### 7.2 卷积神经网络与计算机视觉

| 论文 | 作者 | 主题 |
|------|------|------|
| ImageNet Classification with Deep CNNs (AlexNet) | Krizhevsky, Sutskever, Hinton | 图像分类开创性工作 |
| Deep Residual Learning for Image Recognition (ResNet) | He et al. | 残差学习框架 |
| Identity Mappings in Deep Residual Networks | He et al. | ResNet 增强 |
| Multi-Scale Context Aggregation by Dilated Convolutions | Fisher Yu, Vladlen Koltun | 空洞卷积 |
| CS231n: CNNs for Visual Recognition | Stanford University | 综合课程 |

### 7.3 循环神经网络与序列模型

| 论文/资源 | 作者 | 主题 |
|-----------|------|------|
| The Unreasonable Effectiveness of RNNs | Andrej Karpathy | RNN 能力探索（博客） |
| Understanding LSTM Networks | Christopher Olah | LSTM 详解（博客） |
| Recurrent Neural Network Regularization | Zaremba, Sutskever, Vinyals | RNN 正则化 |
| Order Matters: Sequence to Sequence for Sets | Vinyals, Bengio, Kudlur | 序列顺序重要性 |
| Pointer Networks | Vinyals, Fortunato, Jaitly | 指针网络 |
| Neural Machine Translation by Jointly Learning to Align and Translate | Bahdanau, Cho, Bengio | 注意力机制 |

### 7.4 注意力机制与 Transformer

| 论文/资源 | 作者 | 主题 |
|-----------|------|------|
| **Attention Is All You Need** | Vaswani et al. | Transformer 架构 |
| The Annotated Transformer | Sasha Rush et al. | Transformer 详细实现注解 |

### 7.5 规模化与系统

| 论文 | 作者 | 主题 |
|------|------|------|
| GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism | Huang et al. | 分布式训练 |
| Deep Speech 2 | Amodei et al. | 端到端语音识别 |
| **Scaling Laws for Neural Language Models** | Kaplan et al. | 规模定律 |

### 7.6 关系推理与记忆

| 论文 | 作者 | 主题 |
|------|------|------|
| Neural Turing Machines | Graves, Wayne, Danihelka | 可学习算法任务 |
| A Simple Neural Network Module for Relational Reasoning | Santoro et al. | 关系推理 |
| Relational Recurrent Neural Networks | Santoro et al. | 关系+循环架构 |
| Variational Lossy Autoencoder | Chen et al. | 有损压缩 |
| Neural Message Passing for Quantum Chemistry | Gilmer et al. | 量子化学应用 |

### 7.7 复杂性与理论

| 论文 | 作者 | 主题 |
|------|------|------|
| The First Law of Complexodynamics | Scott Aaronson | 复杂性行为 |
| Quantifying the Rise and Fall of Complexity in Closed Systems | Aaronson, Schulman, Vazirani | 复杂性动力学 |

> 完整列表与学习路径：[GitHub - Ilya Sutskever Reading List](https://github.com/Justmalhar/ilya-sutskever-reading-list)

---

## 8. 参考链接汇总

### 官方资源

- [Ilya Sutskever - 多伦多大学主页](https://www.cs.toronto.edu/~ilya/)
- [Google Scholar 论文列表](https://scholar.google.com/citations?user=x04W_mMAAAAJ)
- [Safe Superintelligence Inc.](https://ssi.inc/)

### 传记与报道

- [Wikipedia - Ilya Sutskever](https://en.wikipedia.org/wiki/Ilya_Sutskever)
- [Royal Society Profile](https://royalsociety.org/people/ilya-sutskever-35834/)
- [The Guardian Documentary](https://www.theguardian.com/technology/video/2023/nov/02/ilya-the-ai-scientist-shaping-the-world)

### 重要事件报道

- [AP News - 离开 OpenAI](https://apnews.com/article/419276b50007ad41adfd27764da3188c)
- [Time - SSI 成立](https://time.com/6990076/safe-superintelligence-inc-announced/)
- [Time - Sam Altman 事件](https://time.com/6337102/sam-altman-departs-openai/)

### 学习资源

- [Ilya Sutskever Reading List (GitHub)](https://github.com/Justmalhar/ilya-sutskever-reading-list)
- [Aman's AI Journal - Top 30 Papers](https://aman.ai/primers/ai/top-30-papers)
- [博士论文 PDF](https://www.cs.toronto.edu/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)

### 视频与播客

**YouTube**
- [Lex Fridman Podcast #94 - Deep Learning](https://lexfridman.com/ilya-sutskever/)
- [NeurIPS 2024 Keynote](https://www.youtube.com/watch?v=YM_8mBnv-EI)
- [TED Talk - The Exciting, Perilous Journey Toward AGI](https://www.youtube.com/watch?v=SEkGLj0bwAU)
- [The Guardian Documentary - Ilya: The AI Scientist](https://www.theguardian.com/technology/video/2023/nov/02/ilya-the-ai-scientist-shaping-the-world)
- [SSI 公司成立公告](https://www.youtube.com/watch?v=_esucEIgIeg)

**播客**
- [Dwarkesh Podcast (2023)](https://www.dwarkeshpatel.com/p/ilya-sutskever)
- [Stanford eCorner - Inside OpenAI](https://stvp.stanford.edu/videos/inside-openai-entire-talk/)

**Bilibili（中文字幕）**
- [多伦多大学荣誉学位演讲](https://www.bilibili.com/video/BV1WQT6zxEun/)
- [黄仁勋与 Ilya 炉边谈话](https://www.bilibili.com/video/BV1Tc411L7UA/)
- [深度访谈：AGI、ChatGPT 与机器人](https://www.bilibili.com/video/BV1pF4m1j7Kb/)
- [斯坦福大学完整演讲](https://www.bilibili.com/video/BV1Y24y1F72o/)

---

## 附录：为什么学习 Ilya Sutskever 的资料对理解 AI 发展很有价值

1. **见证深度学习革命**：作为 AlexNet 的核心开发者之一，他亲身参与了2012年深度学习革命的起点

2. **师承关系**：作为 Geoffrey Hinton（2024年诺贝尔物理学奖得主）的博士生，他的学术脉络可以追溯到现代神经网络的源头

3. **技术领导力**：作为 OpenAI 首席科学家，他领导了从 GPT-1 到 GPT-4 的发展，是大语言模型时代的关键推动者

4. **前沿思考**：他对 AI 意识、超级智能安全的思考代表了领域内最前沿的技术哲学

5. **推荐阅读列表**：他的30篇必读论文列表是学习现代 AI 的优质路线图

---

*本文档基于公开资料整理，如有遗漏或错误，欢迎补充更正。*
